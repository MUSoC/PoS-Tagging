import re

def word_tokenize(text):
    return text.split()
